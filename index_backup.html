

<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
    <title>Jimei Yang - Research Scientist, Adobe Research </title>
<style type="text/css"></style></head>
<body><table border="0" width="980px" align="center"><tbody><tr><td>

    </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
            <img src="images/rilogo.png"> -->
    <br>
    <table style="font-size: 11pt;" border="0" width="100%">
        <tbody><tr>
            <td>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                    <b>Jimei Yang</b><br><br>
                </font>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                    Senior Research Scientist and Manager<br>
                    Adobe Research<br>
                    San Jose, CA<br><br>
                    jimyang at adobe.com<br>
                    [<a href="https://scholar.google.com/citations?user=GwKF9rMAAAAJ&hl=en" border="0">Google Scholar</a>]
                    [<a href="https://www.linkedin.com/in/jimei-yang-841b3722/" border="0">LinkedIn</a>]
                    [<a href="https://twitter.com/jimei_yang" border="0">Twitter</a>]
                </font>
            </td>
            <td width="50%">
                <img width="250" src="./contents/jimeiyang.jpg" border="0">
            </td>
        </tr>
    </tbody></table> 
    <p>
    </p><hr size="2" align="left" noshade="">
    <p>
    
    <h2>Research </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
    <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
    My research mission is learning fundamental structures from large-scale visual data that connect real and virtual worlds and solving problems in human sensing, character animation, image and video synthesis.
    <!-- <br><br> -->
    </p><hr size="2" align="left" noshade="">

    <h2>Highlights </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <span style="font-size: 10pt;">
        <li>Our pose-based image search work, <a href="https://youtu.be/rngRa4M1v-k">Project OnPoint</a> was featured at Adobe MAX Sneaks 2021.</li>
        <li>Our webcam-based real-time body animation technology was shipped in <a href="https://pages.adobe.com/character/en/body-tracker">Adobe Character Animator</a>.</li>
        <li>Our dance video editing technology, <a href="https://youtu.be/NMHLAVjyFxo"> Project On-The-Beat</a> was featured at Adobe MAX Sneaks 2020, and covered by <a href="https://www.protocol.com/adobe-max-ai-video-editing"> Protocol</a>.</li>
        <li>Our video-based motion capture technology was published at ECCV 2020 as <a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/"> Spotlight</a>, and covered by <a href="https://syncedreview.com/2020/07/27/adobe-and-stanford-unveil-sota-method-for-human-pose-estimation/"> Synced</a></li>
        <li>Our body tracking technology in After Effects, <a href="https://youtu.be/xEdZOifROmk"> Project GoFigure</a> was featured at Adobe MAX Sneaks 2019 , and covered by <a href="https://www.theverge.com/2019/11/5/20938360/adobe-max-after-effects-sneaks-body-tracker-feature-animations"> The Verge</a>.</li>
        </span>

    </p><hr size="2" align="left" noshade="">

    <h2>Selected Publications </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="15">
            <tbody>
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Audio-driven Neural Gesture Reenactment with Video Motion Graphs</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://people.umass.edu/~yangzhou/">Yang Zhou</a>,
                    Jimei Yang,
                    <a href="https://dingzeyu.li/">Dingzeyu Li</a>,
                    <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>,
                    <a href="https://research.adobe.com/person/deepali-aneja/">Deepali Aneja</a>,
                    <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a><br>
                    to appear in CVPR, 2022. <br>
                    [<a href="">Paper</a>]
                    [<a href="">Webpage</a>]
                    [<a href="">GitHub</a>]
                    [<a href="">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>HuMoR: 3D Human Motion Model for Robust Pose Estimation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://davrempe.github.io/">Davis Rempe</a>,
                    <a href="https://geometry.stanford.edu/member/tolga/">Tolga Birdal</a>,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    Jimei Yang,
                    <a href="http://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a>,
                    <a href="https://geometry.stanford.edu/member/guibas/">Leonidas J. Guibas</a><br>
                    in ICCV (oral), 2021. <br>
                    [<a href="https://geometry.stanford.edu/projects/humor/docs/humor.pdf">Paper</a>]
                    [<a href="https://geometry.stanford.edu/projects/humor/">Webpage</a>]
                    [<a href="https://github.com/davrempe/humor">GitHub</a>]
                    [<a href="https://youtu.be/oQt6xSNxm0A">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Contact and Human Dynamics from Monocular Video</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://davrempe.github.io/">Davis Rempe</a>,
                    <a href="https://geometry.stanford.edu/member/guibas/">Leonidas J. Guibas</a>,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    <a href="https://bryanrussell.org/">Bryan Russell</a>,
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>,
                    Jimei Yang
                    <br>
                    in ECCV (spotlight), 2020. <br>
                    [<a href="https://arxiv.org/abs/2007.11678">Paper</a>]
                    [<a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/">Webpage</a>]
                    [<a href="https://github.com/davrempe/contact-human-dynamics">GitHub</a>]
                    [<a href="https://youtu.be/qR9KW6JzXX4">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Statistics-based Motion Synthesis for Social Conversations</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yangyanzhe.github.io/">Yanzhe Yang</a>,
                    Jimei Yang,
                    <a href="https://www.cs.cmu.edu/~jkh/">Jessica K. Hodgins</a>,
                    <br>
                    in SCA, 2020. <br>
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/supp/Yang2020.pdf">Paper</a>]
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/">Webpage</a>]
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/supp/supp_01_main.mp4">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Attribute-Conditioned Layout GAN for Automatic Graphic Design</b> <br>
                    <span style="font-size: 10pt;">
                    Jianan Li,
                    Jimei Yang,
                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>,
                    Chang Liu,
                    Christina Wang,
                    Tingfa Xu
                    <br>
                    in IEEE Transactions on Visualization and Computer Graphics, 2020. <br>
                    [<a href="https://ieeexplore.ieee.org/abstract/document/9106863">Paper</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators</b> <br>
                    <span style="font-size: 10pt;">
                    Jianan Li,
                    Jimei Yang,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>,
                    Tingfa Xu
                    <br>
                    in ICLR, 2019. <br>
                    [<a href="https://arxiv.org/abs/1901.06767">Paper</a>]
                    [<a href="https://github.com/JiananLi2016/LayoutGAN-Tensorflow">GitHub</a>]
                    [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948239">Journal version</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Free-Form Image Inpainting with Gated Convolution</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://jiahuiyu.com/">Jiahui Yu</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>,
                    Xin Lu,
                    <a href="https://en.wikipedia.org/wiki/Thomas_Huang">Thomas Huang</a>,
                    <br>
                    in ICCV (oral), 2019. <br>
                    [<a href="https://arxiv.org/abs/1806.03589">Paper</a>]
                    [<a href="https://github.com/JiahuiYu/generative_inpainting">GitHub</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Generative Image Inpainting with Contextual Attention</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://jiahuiyu.com/">Jiahui Yu</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>,
                    Xin Lu,
                    <a href="https://en.wikipedia.org/wiki/Thomas_Huang">Thomas Huang</a>,
                    <br>
                    in CVPR, 2018. <br>
                    [<a href="https://arxiv.org/abs/1801.07892">Paper</a>]
                    [<a href="https://github.com/JiahuiYu/generative_inpainting">GitHub</a>]
                    <br>
                </td>
            </tr>

        </tbody></table>

    <h2>Awards </h2>
    <span style="font-size: 10pt;">
    <a href="">Adobe Tech Excellence Award </a> 2022
 

</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>

