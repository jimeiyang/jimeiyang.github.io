

<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
    <title>Jimei Yang - Research Scientist, Adobe Research </title>
<style type="text/css"></style></head>
<body><table border="0" width="980px" align="center"><tbody><tr><td>

    </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
            <img src="images/rilogo.png"> -->
    <br>
    <table style="font-size: 11pt;" border="0" width="100%">
        <tbody><tr>
            <td>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                    <b>Jimei Yang</b><br><br>
                </font>
                <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                    Senior Research Scientist and Manager<br>
                    Adobe Research<br>
                    San Jose, CA<br><br>
                    jimyang at adobe.com<br>
                    [<a href="https://scholar.google.com/citations?user=GwKF9rMAAAAJ&hl=en" border="0">Google Scholar</a>]
                    [<a href="https://www.linkedin.com/in/jimei-yang-841b3722/" border="0">LinkedIn</a>]
                    [<a href="https://twitter.com/jimei_yang" border="0">Twitter</a>]
                </font>
            </td>
            <td width="50%">
                <img width="250" src="./contents/jimeiyang.jpg" border="0">
            </td>
        </tr>
    </tbody></table> 
    <p>
    </p><hr size="2" align="left" noshade="">
    <p>
    
    <h2>Research </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
    <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
    My research mission is learning fundamental structures from large-scale visual data that connect real and virtual worlds and solving problems in human sensing, character animation, image and video synthesis.
    <!-- <br><br> -->
    </p><hr size="2" align="left" noshade="">

    <h2>Highlights </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <span style="font-size: 10pt;">
        <li>Our pose-based image search work, <a href="https://youtu.be/rngRa4M1v-k">Project OnPoint</a> was featured at Adobe MAX Sneaks 2021.</li>
        <li>Our webcam-based real-time body animation technology was shipped in <a href="https://pages.adobe.com/character/en/body-tracker">Adobe Character Animator</a>.</li>
        <li>Our dance video editing technology, <a href="https://youtu.be/NMHLAVjyFxo"> Project On-The-Beat</a> was featured at Adobe MAX Sneaks 2020, and covered by <a href="https://www.protocol.com/adobe-max-ai-video-editing"> Protocol</a>.</li>
        <li>Our video-based motion capture technology was published at ECCV 2020 as <a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/"> Spotlight</a>, and covered by <a href="https://syncedreview.com/2020/07/27/adobe-and-stanford-unveil-sota-method-for-human-pose-estimation/"> Synced</a></li>
        <li>Our body tracking technology in After Effects, <a href="https://youtu.be/xEdZOifROmk"> Project GoFigure</a> was featured at Adobe MAX Sneaks 2019 , and covered by <a href="https://www.theverge.com/2019/11/5/20938360/adobe-max-after-effects-sneaks-body-tracker-feature-animations"> The Verge</a>.</li>
        </span>

    </p><hr size="2" align="left" noshade="">

    <h2>Selected Publications </h2>
    <font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="15">
            <tbody>
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Audio-driven Neural Gesture Reenactment with Video Motion Graphs</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://people.umass.edu/~yangzhou/">Yang Zhou</a>,
                    Jimei Yang,
                    <a href="https://dingzeyu.li/">Dingzeyu Li</a>,
                    <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>,
                    <a href="https://research.adobe.com/person/deepali-aneja/">Deepali Aneja</a>,
                    <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a><br>
                    to appear in CVPR, 2022. <br>
                    [<a href="">Paper</a>]
                    [<a href="">Webpage</a>]
                    [<a href="">GitHub</a>]
                    [<a href="">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Pose with Style: Detail-Preserving Pose-Guided Image Synthesis with Conditional StyleGAN</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://badouralbahar.github.io/">Badour AlBahar</a>,
                    <a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a>,
                    Jimei Yang,
                    <a href="https://zhixinshu.github.io/">Zhixin Shu</a>,
                    <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>,
                    <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>
                    <br>
                    in SIGGRAPH Asia, 2021. <br>
                    [<a href="https://arxiv.org/abs/2109.06166">Paper</a>]
                    [<a href="https://pose-with-style.github.io/">GitHub</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>HuMoR: 3D Human Motion Model for Robust Pose Estimation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://davrempe.github.io/">Davis Rempe</a>,
                    <a href="https://geometry.stanford.edu/member/tolga/">Tolga Birdal</a>,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    Jimei Yang,
                    <a href="http://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a>,
                    <a href="https://geometry.stanford.edu/member/guibas/">Leonidas J. Guibas</a><br>
                    in ICCV (oral), 2021. <br>
                    [<a href="https://geometry.stanford.edu/projects/humor/docs/humor.pdf">Paper</a>]
                    [<a href="https://geometry.stanford.edu/projects/humor/">Webpage</a>]
                    [<a href="https://github.com/davrempe/humor">GitHub</a>]
                    [<a href="https://youtu.be/oQt6xSNxm0A">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Stochastic Scene-Aware Motion Prediction</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://mohamedhassanmus.github.io/">Mohamed Hassan</a>,
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>,
                    <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>,
                    Jimei Yang,
                    <a href="https://zhouyisjtu.github.io/">Yi Zhou</a>,
                    <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael Black</a>
                    <br>
                    in ICCV, 2021. <br>
                    [<a href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/652/samp.pdf">Paper</a>]
                    [<a href="https://samp.is.tue.mpg.de/">Webpage</a>]
                    [<a href="https://github.com/mohamedhassanmus/SAMP">GitHub</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Contact-Aware Retargetting of Skinned Motion</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>,
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    Jimei Yang,
                    <a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>
                    <br>
                    in ICCV, 2021. <br>
                    [<a href="https://arxiv.org/abs/2108.08284">Paper</a>]
                    [<a href="https://sites.google.com/umich.edu/camr">Webpage</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Interactive Liquid Splash Modeling by User Sketches</b> <br>
                    <span style="font-size: 10pt;">
                    Guowei Yan,
                    Zhili Chen,
                    Jimei Yang,
                    <a href="https://web.cse.ohio-state.edu/~wang.3602/">Huamin Wang</a>
                    <br>
                    in SIGGRAPH Asia, 2020. <br>
                    [<a href="https://dl.acm.org/doi/abs/10.1145/3414685.3417832">Paper</a>]
                    [<a href="https://youtu.be/HXAxNrfk_w0">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Contact and Human Dynamics from Monocular Video</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://davrempe.github.io/">Davis Rempe</a>,
                    <a href="https://geometry.stanford.edu/member/guibas/">Leonidas J. Guibas</a>,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    <a href="https://bryanrussell.org/">Bryan Russell</a>,
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>,
                    Jimei Yang
                    <br>
                    in ECCV (spotlight), 2020. <br>
                    [<a href="https://arxiv.org/abs/2007.11678">Paper</a>]
                    [<a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/">Webpage</a>]
                    [<a href="https://github.com/davrempe/contact-human-dynamics">GitHub</a>]
                    [<a href="https://youtu.be/qR9KW6JzXX4">Video</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://zengxianyu.github.io/">Yu Zeng</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>,
                    <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>,
                    Huchuan Lu
                    <br>
                    in ECCV, 2020. <br>
                    [<a href="https://arxiv.org/abs/2005.11742">Paper</a>]
                    [<a href="https://zengxianyu.github.io/iic/">Webpage</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Statistics-based Motion Synthesis for Social Conversations</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yangyanzhe.github.io/">Yanzhe Yang</a>,
                    Jimei Yang,
                    <a href="https://www.cs.cmu.edu/~jkh/">Jessica K. Hodgins</a>
                    <br>
                    in SCA, 2020. <br>
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/supp/Yang2020.pdf">Paper</a>]
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/">Webpage</a>]
                    [<a href="http://www.cs.cmu.edu/~dyadic-conversation/supp/supp_01_main.mp4">Video</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Attribute-Conditioned Layout GAN for Automatic Graphic Design</b> <br>
                    <span style="font-size: 10pt;">
                    Jianan Li,
                    Jimei Yang,
                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>,
                    Chang Liu,
                    Christina Wang,
                    Tingfa Xu
                    <br>
                    in IEEE Transactions on Visualization and Computer Graphics, 2020. <br>
                    [<a href="https://ieeexplore.ieee.org/abstract/document/9106863">Paper</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>3D Ken Burns Effect from a Single Image</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="http://sniklaus.com/">Simon Niklaus</a>,
                    Long Mai,
                    Jimei Yang,
                    <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a>
                    <br>
                    in SIGGRAPH Asia, 2019. <br>
                    [<a href="https://arxiv.org/abs/1909.05483">Paper</a>]
                    [<a href="http://sniklaus.com/papers/kenburns/">Webpage</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Free-Form Image Inpainting with Gated Convolution</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://jiahuiyu.com/">Jiahui Yu</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>,
                    Xin Lu,
                    <a href="https://en.wikipedia.org/wiki/Thomas_Huang">Thomas Huang</a>
                    <br>
                    in ICCV (oral), 2019. <br>
                    [<a href="https://arxiv.org/abs/1806.03589">Paper</a>]
                    [<a href="https://github.com/JiahuiYu/generative_inpainting">GitHub</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape from Single RGB Images</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="http://sniklaus.com/">Christian Zimmermann</a>,
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                    Jimei Yang,
                    <a href="https://bryanrussell.org/">Bryan Russell</a>,
                    <a href="https://lmb.informatik.uni-freiburg.de/people/argusm/">Max Argus</a>,
                    <a href="https://lmb.informatik.uni-freiburg.de/people/brox/">Thomas Brox</a>
                    <br>
                    in ICCV, 2019. <br>
                    [<a href="https://arxiv.org/abs/1909.05483">Paper</a>]
                    [<a href="https://lmb.informatik.uni-freiburg.de/projects/freihand/">Webpage</a>]
                    [<a href="https://github.com/lmb-freiburg/freihand">GitHub</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Multimodal Style Transfer via Graph Cuts</b> <br>
                    <span style="font-size: 10pt;">
                    Yulun Zhang,
                    Chen Fang,
                    Yilin Wang,
                    <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    <a href="http://www1.ece.neu.edu/~yunfu/">Yun Fu</a>
                    Jimei Yang
                    <br>
                    in ICCV, 2019. <br>
                    [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Multimodal_Style_Transfer_via_Graph_Cuts_ICCV_2019_paper.pdf">Paper</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Foreground-aware Image Inpainting</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://wxiong.me/">Wei Xiong</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    Xin Lu,
                    <a href="http://www.connellybarnes.com/work/">Connelly Barnes</a>,
                    <a href="https://www.cs.rochester.edu/u/jluo/">Jiebo Luo</a>
                    <br>
                    in CVPR, 2019. <br>
                    [<a href="https://arxiv.org/abs/1901.05945">Paper</a>]
                    [<a href="https://wxiong.me/foreground/">Webpage</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>On the Continuity of Rotation Representations in Neural Networks</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://zhouyisjtu.github.io/">Yi Zhou</a>,
                    <a href="http://www.connellybarnes.com/work/">Connelly Barnes</a>,
                    <a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a>,
                    Jimei Yang,
                    <a href="http://www.hao-li.com/">Hao Li</a>
                    <br>
                    in CVPR, 2019. <br>
                    [<a href="https://arxiv.org/abs/1901.05945">Paper</a>]
                    [<a href="https://wxiong.me/foreground/">Webpage</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators</b> <br>
                    <span style="font-size: 10pt;">
                    Jianan Li,
                    Jimei Yang,
                    <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>,
                    Tingfa Xu
                    <br>
                    in ICLR, 2019. <br>
                    [<a href="https://arxiv.org/abs/1901.06767">Paper</a>]
                    [<a href="https://github.com/JiananLi2016/LayoutGAN-Tensorflow">GitHub</a>]
                    [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948239">Journal version</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>BodyNet: Volumetric Inference of 3D Human Body Shapes</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://gulvarol.github.io/">GÃ¼l Varol</a>,
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>,
                    <a href="https://bryanrussell.org/">Bryan Russell</a>,
                    Jimei Yang,
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>,
                    <a href="https://www.di.ens.fr/~laptev//">Ivan Laptev</a>,
                    <a href="http://lear.inrialpes.fr/~schmid/">Cordelia Schmid</a>
                    <br>
                    in ECCV, 2018. <br>
                    [<a href="https://arxiv.org/abs/1804.04875">Paper</a>]
                    [<a href="https://github.com/gulvarol/bodynet">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Flow-Grounded Spatial-Temporal Video Prediction from Still Images</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
                    Chen Fang,
                    Jimei Yang,
                    <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>,
                    Xin Lu,
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                    <br>
                    in ECCV, 2018. <br>
                    [<a href="https://arxiv.org/abs/1807.09755">Paper</a>]
                    [<a href="https://github.com/Yijunmaverick/FlowGrounded-VideoPrediction">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Brush Stroke Synthesis with a Generative Adversarial Network Driven by Physically Based Simulation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://www.cs.cornell.edu/~rundongwu/">Rundong Wu</a>,
                    Zhili Chen, 
                    <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>, 
                    Jimei Yang, 
                    <a href="https://www.cs.cornell.edu/~srm/">Steve Marschner</a>
                    <br>
                    in Expressive, 2018. <br>
                    [<a href="https://dl.acm.org/citation.cfm?id=3229150">Paper</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Generative Image Inpainting with Contextual Attention</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://jiahuiyu.com/">Jiahui Yu</a>,
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>,
                    Jimei Yang,
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>,
                    Xin Lu,
                    <a href="https://en.wikipedia.org/wiki/Thomas_Huang">Thomas Huang</a>
                    <br>
                    in CVPR, 2018. <br>
                    [<a href="https://arxiv.org/abs/1801.07892">Paper</a>]
                    [<a href="https://github.com/JiahuiYu/generative_inpainting">GitHub</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Neural Kinematic Networks for Unsupervised Motion Retargeting</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>, 
                    Jimei Yang, 
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>, 
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in CVPR (oral), 2018. <br>
                    [<a href="https://arxiv.org/abs/1807.09755">Paper</a>]
                    [<a href="https://sites.google.com/umich.edu/nik">Webpage</a>]
                    [<a href="https://github.com/rubenvillegas/cvpr2018nkn">Github</a>]
                    <br>
                </td>
            </tr> 
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="http://art-programmer.github.io/">Chen Liu</a>, 
                    Jimei Yang, 
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>, 
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>, 
                    <a href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a>
                    <br>
                    in CVPR (spotlight), 2018. <br>
                    [<a href="https://arxiv.org/abs/1804.06278">Paper</a>]
                    [<a href="http://art-programmer.github.io/planenet.html">Webpage</a>]
                    [<a href="https://github.com/art-programmer/PlaneNet">Github</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>MatNet: Modular Attention Network for Referring Expression Comprehension</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://lichengunc.github.io/">Licheng Yu</a>, 
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>, 
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>, 
                    Jimei Yang, 
                    Xin Lu, 
                    <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>>, 
                    <a href="http://tamaraberg.com/">Tamara Berg</a>
                    <br>
                    in CVPR, 2018. <br>
                    [<a href="https://arxiv.org/abs/1801.08186">Paper</a>]
                    [<a href="http://vision2.cs.unc.edu/refer/">Webpage</a>]
                    [<a href="https://github.com/lichengunc/MAttNet">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Universal Style Transfer via Feature Transforms</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
                    Chen Fang,
                    Jimei Yang,
                    <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>,
                    Xin Lu,
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                    <br>
                    in NeurIPS, 2017. <br>
                    [<a href="https://arxiv.org/abs/1705.08086">Paper</a>]
                    [<a href="https://github.com/Yijunmaverick/UniversalStyleTransfer">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://liuguilin1225.github.io/">Guilin Liu</a>,  
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>, 
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>, 
                    Jimei Yang,
                    <a href="https://cs.gmu.edu/~jmlien/doku.php">Jyh-Ming Lien</a>
                    <br>
                    in ICCV (spotlight), 2017. <br>
                    [<a href="https://arxiv.org/abs/1708.00106">Paper</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Recurrent Multimodal Interaction for Referring Image Segmentation</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://www.cs.jhu.edu/~cxliu/">Chenxi Liu</a>, 
                    <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>, 
                    <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a>, 
                    Jimei Yang, 
                    Xin Lu, 
                    <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
                    <br>
                    in ICCV, 2017. <br>
                    [<a href="https://arxiv.org/abs/1703.07939">Paper</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>3D-PRNN: Generating Shape Primitives With Recurrent Neural Networks</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://zouchuhang.github.io/">Chuhang Zou</a>, 
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>, 
                    Jimei Yang, 
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>, 
                    <a href="https://dhoiem.cs.illinois.edu/">Derek Hoiem</a>
                    <br>
                    in ICCV, 2017. <br>
                    [<a href="https://arxiv.org/abs/1708.01648">Paper</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Learning to Generate Long-term Future via Hierarchical Prediction</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>, 
                    Jimei Yang, 
                    <a href="https://yuliang.vision/">Yuliang Zou</a>, 
                    <a href="https://sites.google.com/view/sungryull">Sungryull Sohn</a>, 
                    Xunyu Lin, 
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in ICML, 2017. <br>
                    [<a href="https://arxiv.org/abs/1704.05831">Paper</a>]
                    [<a href="https://sites.google.com/a/umich.edu/rubenevillegas/hierch_vid">Webpage</a>]
                    [<a href="https://github.com/rubenvillegas/icml2017hierchvid">Github</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Transformation-Grounded Image Generation Network for Novel 3D View Synthesis</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://silverbottlep.github.io/">Eunbyung Park</a>, 
                    Jimei Yang, 
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>, 
                    <a href="http://www.duygu-ceylan.com/">Duygu Ceylan</a>, 
                    <a href="http://acberg.com/">Alex Berg</a>
                    <br>
                    in CVPR, 2017. <br>
                    [<a href="https://arxiv.org/abs/1704.05831">Paper</a>]
                    [<a href="https://www.cs.unc.edu/~eunbyung/tvsn/">Webpage</a>]
                    [<a href="https://github.com/silverbottlep/tvsn">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Forecasting Human Dynamics from Static Images</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://research.nvidia.com/person/yuwei-chao">Yu-Wei Chao</a>, 
                    Jimei Yang, 
                    <a href="https://www.brianpricephd.com/">Brian Price</a>, 
                    <a href="https://research.adobe.com/person/scott-cohen/">Scott Cohen</a>,
                    <a href="https://web.eecs.umich.edu/~jiadeng/">Jia Deng</a>
                    <br>
                    in CVPR, 2017. <br>
                    [<a href="https://arxiv.org/abs/1704.03432">Paper</a>]
                    [<a href="http://www-personal.umich.edu/~ywchao/image-play/">Webpage</a>]
                    [<a href="https://github.com/ywchao/image-play">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Generative Face Completion</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
                    <a href="https://www.sifeiliu.net/">Sifei Liu</a>, 
                    Jimei Yang, 
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                    <br>
                    in CVPR, 2017. <br>
                    [<a href="https://arxiv.org/abs/1704.05838">Paper</a>]
                    [<a href="https://sites.google.com/site/yijunlimaverick/facecompletion">Webpage</a>]
                    [<a href="https://github.com/Yijunmaverick/GenerativeFaceCompletion">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Diversified Texture Synthesis with Feed-forward Networks</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
                    Chen Fang, 
                    Jimei Yang, 
                    <a href="https://research.adobe.com/person/zhaowen-wang/">Zhaowen Wang</a>, 
                    Xin Lu, 
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                    <br>
                    in CVPR (spotlight), 2017. <br>
                    [<a href="https://arxiv.org/abs/1703.01664">Paper</a>]
                    [<a href="https://sites.google.com/site/yijunlimaverick/texturesynthesis">Webpage</a>]
                    [<a href="https://github.com/Yijunmaverick/MultiTextureSynthesis">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Decomposing Motion and Content for Natural Video Sequence Prediction</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://rubenvillegas.me/">Ruben Villegas</a>, 
                    Jimei Yang,  
                    <a href="https://maga33.github.io/">Seunghoon Hong</a>, 
                    Xunyu Lin, 
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in ICLR, 2017. <br>
                    [<a href="https://arxiv.org/abs/1706.08033">Paper</a>]
                    [<a href="https://sites.google.com/a/umich.edu/rubenevillegas/iclr2017">Webpage</a>]
                    [<a href="https://github.com/rubenvillegas/iclr2017mcnet">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://sites.google.com/site/skywalkeryxc/">Xinchen Yan</a>, 
                    Jimei Yang, 
                    <a href="http://www.meyumer.com/">Ersin Yumer</a>, 
                    <a href="https://www.guoyijie.me/">Yijie Guo</a>,
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in NeurIPS, 2016. <br>
                    [<a href="https://arxiv.org/abs/1612.00814">Paper</a>]
                    [<a href="https://github.com/xcyan/nips16_PTN">Github</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Attribute2Image: Conditional Image Generation from Visual Attributes</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://sites.google.com/site/skywalkeryxc/">Xinchen Yan</a>, 
                    Jimei Yang, 
                    <a href="https://sites.google.com/site/kihyuksml/">Kihyuk Sohn</a>,
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in ECCV, 2016. <br>
                    [<a href="https://arxiv.org/abs/1512.00570">Paper</a>]
                    [<a href="https://sites.google.com/site/attribute2image/">Webpage</a>]
                    [<a href="https://github.com/xcyan/attr2img/">Github</a>]
                    [<a href="https://www.youtube.com/watch?v=Hp5qknteQ1o">Video</a>]
                    <br>
                </td>
            </tr>
            
            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Object Contour Detection with a Fully Convolutional Encoder-Decoder Network</b> <br>
                    <span style="font-size: 10pt;">
                    Jimei Yang, 
                    <a href="https://www.brianpricephd.com/">Brian Price</a>, 
                    <a href="https://research.adobe.com/person/scott-cohen/">Scott Cohen</a>, 
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>, 
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                    <br>
                    in CVPR (spotlight), 2016. <br>
                    [<a href="http://arxiv.org/abs/1603.04530">Paper</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Deep Interactive Object Selection</b> <br>
                    <span style="font-size: 10pt;">
                    <a href="https://sites.google.com/view/ningxu/">Ning Xu</a>, 
                    <a href="https://www.brianpricephd.com/">Brian Price</a>, 
                    <a href="https://research.adobe.com/person/scott-cohen/">Scott Cohen</a>, 
                    Jimei Yang, 
                    <a href="https://en.wikipedia.org/wiki/Thomas_Huang">Thomas Huang</a>
                    <br>
                    in CVPR, 2016. <br>
                    [<a href="https://arxiv.org/abs/1603.04042">Paper</a>]
                    [<a href="https://sites.google.com/view/deepselection">Webpage</a>]
                    <br>
                </td>
            </tr>

            <tr>
                <td>
                    <span style="font-size: 12pt;">
                    <b>Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis</b> <br>
                    <span style="font-size: 10pt;">
                    Jimei Yang, 
                    <a href="http://www.scottreed.info/">Scott Reed</a>, 
                    <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>, 
                    <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
                    <br>
                    in NeuIPS, 2015. <br>
                    [<a href="https://arxiv.org/abs/1601.00706">Paper</a>]
                    [<a href="https://www.youtube.com/watch?v=3dPwiWnDoNY">Video</a>]
                    [<a href="https://github.com/jimeiyang/deepRotator">GitHub</a>]
                    [<a href="https://www.youtube.com/watch?v=gX9rkJsfp2w&amp;index=5&amp;list=PLP2fXYwxWOBL0SYKNBkXBdsiahTPkLZWH">Talk</a>]
                    <br>
                </td>
            </tr>

        </tbody></table>

</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>

